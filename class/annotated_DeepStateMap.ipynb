{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/werowe/deepstate-map-data/blob/main/class/annotated_DeepStateMap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is an extensive explanation of the logic and techniques used in your Jupyter Notebook.\n",
        "\n",
        "Following the explanation, I have provided a **Python script** that you can run to automatically generate the new, heavily annotated .ipynb file.\n",
        "\n",
        "### **Part 1: Detailed Code Explanation**\n",
        "\n",
        "This notebook performs a sophisticated geospatial Extract-Transform-Load (ETL) process. It scrapes live war-zone data, cleanses geometry, verifies data freshness, validates topology, and exports the result.\n",
        "\n",
        "#### **1\\. Data Extraction (The API Hack)**\n",
        "\n",
        "The script essentially \"hacks\" the DeepStateMap frontend by calling its backend API directly.\n",
        "\n",
        "* **Discovery:** The markdown explains using the Browser's \"Network Tab\" to find hidden API calls (XHR/Fetch).  \n",
        "* **Request:** It uses requests.get() to hit https://deepstatemap.live/api/history/last.  \n",
        "* **Significance:** Instead of scraping HTML (which is messy), this retrieves the raw GeoJSON data used to render the map, providing the highest possible fidelity.\n",
        "\n",
        "#### **2\\. Geometry Flattening (The 3D to 2D Fix)**\n",
        "\n",
        "The raw data comes in (Longitude, Latitude, Altitude) or (X, Y, Z) format.\n",
        "\n",
        "* **The Problem:** Most 2D mapping libraries (like Matplotlib or standard Shapefiles) struggle with the Z-axis (Altitude), or it causes errors during topological operations (like intersections).  \n",
        "* **The Solution:** The code uses a serialization trick:  \n",
        "  Python\n",
        "\n",
        "```\n",
        "\n",
        "wkt.loads(wkt.dumps(shape(geom), output_dimension=2))\n",
        "```\n",
        "\n",
        "*   \n",
        "  It converts the shape to a text representation (WKT), forces it to 2 dimensions (dropping Z), and converts it back to a geometric object.\n",
        "\n",
        "#### **3\\. Data Parsing & Translation**\n",
        "\n",
        "The name field in the raw data contains a string separated by /// (e.g., \"Ukrainian Text /// English Text /// Code\").\n",
        "\n",
        "* **Logic:** A custom function extract\\_first\\_part splits this string and grabs index 1 (the English text) to make the dataset internationally readable.\n",
        "\n",
        "#### **4\\. Geospatial Filtering**\n",
        "\n",
        "The dataset contains mixed types: Points (cities, events) and Polygons (territories).\n",
        "\n",
        "* **Type Filtering:** gdf.geometry.apply(lambda x: isinstance(x, Polygon)) creates a mask to keep only territorial shapes, discarding points.  \n",
        "* **Attribute Filtering:** It filters the dataframe for specific keys: \\['CADR and CALR', 'Occupied', 'Occupied Crimea'\\]. This isolates the Russian-controlled territories from liberated or contested zones.\n",
        "\n",
        "#### **5\\. Data Verification (The \"Contains\" Check)**\n",
        "\n",
        "To ensure the map isn't stale, the script performs a \"Point-in-Polygon\" test.\n",
        "\n",
        "* **Control Point:** A hardcoded coordinate (\\_latest\\_rus\\_advance) representing a very recent frontline change is created.  \n",
        "* **Logic:** occupied\\_ua\\_gdf\\_raw.contains(point) checks if this new point physically sits inside the downloaded polygons. If True, the map data is current.\n",
        "\n",
        "#### **6\\. Topological Merging & Repair (The Buffer Trick)**\n",
        "\n",
        "This is the most advanced part of the script.\n",
        "\n",
        "* **Union:** union\\_all() merges hundreds of small polygons into one giant shape (Multipolygon).  \n",
        "* **Artifacts:** Merging often creates \"slivers\" or \"ghost gaps\" due to floating-point math errors at polygon boundaries.  \n",
        "* **The Fix (Buffer/Debuffer):**  \n",
        "  * **Buffer (+$\\\\epsilon$):** Expands the shape outward by a tiny fraction ($0.000009$). This forces edges to overlap and snaps gaps shut.  \n",
        "  * **Buffer (-$\\\\epsilon$):** Shrinks the shape back by the same amount.  \n",
        "  * **Result:** The general shape is preserved, but internal artifacts/holes are healed.\n",
        "\n",
        "#### **7\\. Validation & CRS Projection**\n",
        "\n",
        "* **Projection:** Coordinates are transformed from EPSG:4326 (Lat/Lon, measured in degrees) to EPSG:9835 (a local projection for Donetsk/Ukraine, measured in meters).  \n",
        "* **Area Check:** It calculates the area of the original shape vs. the healed shape. The difference is 0.000027%, proving the repair altered the geometry only microscopically (removing artifacts) without corrupting the data.\n",
        "\n",
        "---\n",
        "\n",
        "### **Part 2: Generator Script**\n",
        "\n",
        "Run the following Python block. It will create a file named annotated\\_DeepStateMap.ipynb in your current directory. This new file contains your original code, but broken down with Markdown cells explaining every step in detail, and inline comments for complex lines."
      ],
      "metadata": {
        "id": "btPe7XMGlt7_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izF9I0QFkSkB"
      },
      "source": [
        "# DeepStateMap Geospatial ETL Pipeline\n",
        "\n",
        "## 1. Environment Setup\n",
        "Importing necessary libraries for HTTP requests (`requests`), handling geospatial dataframes (`geopandas`), geometric manipulation (`shapely`), and visualization (`matplotlib`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0yvycsnkSkD"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import shape\n",
        "from shapely.geometry import Polygon\n",
        "from shapely.geometry import Point\n",
        "from shapely import wkt\n",
        "from shapely.geometry import JOIN_STYLE\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMZZmMo1kSkE"
      },
      "source": [
        "## 2. API Extraction Strategy\n",
        "Instead of scraping HTML, we target the backend API directly. This provides the raw GeoJSON data used by the website to render the map.\n",
        "\n",
        "**Note:** This endpoint (`api/history/last`) retrieves the current state of the map."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WGzuY9JkSkE"
      },
      "outputs": [],
      "source": [
        "url = 'https://deepstatemap.live/api/history/last'\n",
        "\n",
        "# Execute GET request to fetch raw map state\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check HTTP 200 (Success)\n",
        "response.status_code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_TpIApxkSkE"
      },
      "source": [
        "## 3. Data Exploration & parsing\n",
        "We parse the JSON response. The data is nested: `id` -> `map` -> `features`. The `features` list contains the actual geometric data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvbVqczOkSkF"
      },
      "outputs": [],
      "source": [
        "deep_state_data_raw = response.json()\n",
        "\n",
        "# Inspect top-level keys to ensure structure matches expectations\n",
        "print(deep_state_data_raw.keys())\n",
        "print(deep_state_data_raw['map'].keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QuTpmJ5kSkF"
      },
      "source": [
        "## 4. Geometry flattening (3D to 2D)\n",
        "**Critical Step:** The API returns coordinates in `(x, y, z)` format (Longitude, Latitude, Altitude). Most 2D analysis tools fail if Z-coordinates are present.\n",
        "\n",
        "We loop through the features and use `shapely.wkt` to serialize the shape to text while forcing `output_dimension=2`, effectively dropping the Z-axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNuePaHtkSkF"
      },
      "outputs": [],
      "source": [
        "geo_list = []\n",
        "\n",
        "for f in deep_state_data_raw['map']['features']:\n",
        "    geom = f['geometry']\n",
        "    name = f['properties']['name']\n",
        "\n",
        "    # Convert raw dict to Shape object -> Dump to WKT (Text) forcing 2D -> Load back to Shape\n",
        "    # This effectively strips the 'Z' coordinate\n",
        "    clean_geometry = wkt.loads(wkt.dumps(shape(geom), output_dimension=2))\n",
        "\n",
        "    new_feature = {\n",
        "      \"name\": name,\n",
        "      \"geometry\": clean_geometry\n",
        "    }\n",
        "\n",
        "    geo_list.append(new_feature)\n",
        "\n",
        "# Check total count of features retrieved\n",
        "print(f\"Total features extracted: {len(geo_list)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pk2dQ_s2kSkF"
      },
      "source": [
        "## 5. Metadata Translation\n",
        "The `name` field is formatted as `Ukrainian /// English /// Code`. We create a utility to split this string and retain only the English label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lh1TZvuGkSkF"
      },
      "outputs": [],
      "source": [
        "def extract_first_part(name, part=0):\n",
        "    \"\"\"Splits the DeepState name string and returns the specific index requested.\"\"\"\n",
        "    first_part = name.split('///')[part].strip()\n",
        "    return first_part\n",
        "\n",
        "# Apply translation to all items in the list (Index 1 = English)\n",
        "for item in geo_list:\n",
        "    item['name'] = extract_first_part(item['name'], part=1)\n",
        "\n",
        "# Verify the first item is now English\n",
        "print(geo_list[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9-CTHNnkSkG"
      },
      "source": [
        "## 6. GeoDataFrame Construction\n",
        "We convert the list of dicts into a `GeoDataFrame`. We explicitly set the CRS (Coordinate Reference System) to **EPSG:4326** (WGS84 - Standard Latitude/Longitude)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSpJHTCTkSkG"
      },
      "outputs": [],
      "source": [
        "raw_deepstatemap_gdf = gpd.GeoDataFrame(geo_list)\n",
        "raw_deepstatemap_gdf = raw_deepstatemap_gdf.set_crs(4326)\n",
        "\n",
        "# Visual inspection of the raw data\n",
        "raw_deepstatemap_gdf.plot()\n",
        "plt.title(\"Raw Extracted Features\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAON2IplkSkG"
      },
      "source": [
        "## 7. Data Cleaning & Filtering\n",
        "The dataset contains mixed geometries (Points for events/cities, Polygons for territories). We filter to keep **only Polygons**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQ-jn1nDkSkG"
      },
      "outputs": [],
      "source": [
        "# Filter: Keep rows where geometry is a Polygon\n",
        "deepstatemap_gdf = raw_deepstatemap_gdf[\n",
        "    raw_deepstatemap_gdf.geometry.apply(lambda x: isinstance(x, Polygon))\n",
        "].copy()\n",
        "\n",
        "print(f\"Polygons remaining: {len(deepstatemap_gdf)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PCuCBvckSkG"
      },
      "source": [
        "## 8. Identifying Occupied Territories\n",
        "We filter specifically for names associated with Russian occupation (`Occupied`, `Occupied Crimea`, etc). This discards 'Liberated' or 'Grey Zone' areas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKrziTaUkSkG"
      },
      "outputs": [],
      "source": [
        "targets = ['CADR and CALR', 'Occupied', 'Occupied Crimea']\n",
        "\n",
        "occupied_ua_gdf_raw = deepstatemap_gdf[\n",
        "    deepstatemap_gdf['name'].isin(targets)\n",
        "].copy().reset_index()\n",
        "\n",
        "occupied_ua_gdf_raw.plot(cmap='viridis')\n",
        "plt.title(\"Filtered Occupied Territories\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubLXpVhqkSkG"
      },
      "source": [
        "## 9. Data Freshness Verification (Point-in-Polygon)\n",
        "To validate the data is not stale, we define a point (`_latest_rus_advance`) known to be recently occupied.\n",
        "\n",
        "We use the `.contains()` method. If the point lies inside our polygon set, the map data includes the latest updates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_qfKh4YkSkG"
      },
      "outputs": [],
      "source": [
        "# Define a control point (Lat/Lon)\n",
        "_latest_rus_advance = Point(37.50500679016114, 48.21177662359289)\n",
        "\n",
        "# Check if this point exists within any of the occupied polygons\n",
        "is_up_to_date = occupied_ua_gdf_raw.contains(_latest_rus_advance).any()\n",
        "\n",
        "print(f\"Data Freshness Confirmed: {is_up_to_date}\")\n",
        "\n",
        "# Visual Verification\n",
        "fig, ax = plt.subplots()\n",
        "occupied_ua_gdf_raw.plot(ax=ax, alpha=0.5)\n",
        "ax.scatter(_latest_rus_advance.x, _latest_rus_advance.y, color='red', marker='o', label='Latest Advance')\n",
        "\n",
        "# Zoom in on the point\n",
        "buffer = 0.05\n",
        "ax.set_xlim(_latest_rus_advance.x - buffer, _latest_rus_advance.x + buffer)\n",
        "ax.set_ylim(_latest_rus_advance.y - buffer, _latest_rus_advance.y + buffer)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH1eGRe7kSkG"
      },
      "source": [
        "## 10. Topology Repair (The Buffer Trick)\n",
        "We merge all individual polygons into one `MultiPolygon` using `union_all()`. However, computational math often leaves microscopic gaps (slivers) between touching polygons.\n",
        "\n",
        "**The Fix:**\n",
        "1. **Buffer (+epsilon):** Expand the shape slightly to overlap and close gaps.\n",
        "2. **Buffer (-epsilon):** Shrink the shape back to original size.\n",
        "\n",
        "We use `JOIN_STYLE.mitre` to preserve sharp corners."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p739vk_UkSkG"
      },
      "outputs": [],
      "source": [
        "# 1. Create a single fused geometry\n",
        "occupied_ua_gsr = gpd.GeoSeries(occupied_ua_gdf_raw.union_all(), crs=4326)\n",
        "\n",
        "# 2. Apply Buffer/Debuffer trick to remove artifacts\n",
        "eps = 0.000009 # Epsilon value (tiny distance)\n",
        "\n",
        "occupied_ua = (\n",
        "    occupied_ua_gsr\n",
        "    .buffer(eps, 1, join_style=JOIN_STYLE.mitre)  # Expand\n",
        "    .buffer(-eps, 1, join_style=JOIN_STYLE.mitre) # Shrink\n",
        "    .to_crs(4326)\n",
        "    .copy()\n",
        ")\n",
        "\n",
        "# Plot boundaries to ensure no internal artifacts remain\n",
        "occupied_ua.boundary.plot()\n",
        "plt.title(\"Cleaned Geometry Boundaries\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz5REZdxkSkG"
      },
      "source": [
        "## 11. Statistical Validation\n",
        "Did the buffer trick distort the map? We check the area difference.\n",
        "\n",
        "**Note:** We calculate area using `EPSG:9835` (UCS-2000), a projection system specifically accurate for the Donetsk region, rather than using generic Lat/Lon degrees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkLvzk1okSkG"
      },
      "outputs": [],
      "source": [
        "# Calculate area difference between raw and cleaned versions using local projection\n",
        "area_cleaned = occupied_ua.to_crs(9835).area.sum()\n",
        "area_raw = occupied_ua_gsr.to_crs(9835).area.sum()\n",
        "\n",
        "pct_diff = abs((area_cleaned - area_raw) / area_raw) * 100\n",
        "\n",
        "print(f\"Area Difference: {pct_diff:.6f}%\")\n",
        "if pct_diff < 0.01:\n",
        "    print(\"Validation Passed: Topology repair did not distort geometry.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTAI8DAvkSkG"
      },
      "source": [
        "## 12. Export\n",
        "Saving the finalized, cleaned, and verified geometry to GeoJSON."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5LoSCd8kSkG"
      },
      "outputs": [],
      "source": [
        "occupied_ua.to_crs(4326).to_file(\"occupied-areas-ua.geojson\", driver=\"GeoJSON\")\n",
        "print(\"Export Complete.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}